{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87b91d83",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "### Understanding Uncertainty\n",
    "### Due 9/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380e339f",
   "metadata": {},
   "source": [
    "1. Create a new public repo on Github under your account. Include a readme file.\n",
    "2. Clone it to your machine. Put this file into that repo.\n",
    "3. Use the following function to download the example data for the course:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d62b4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download file already exists\n",
      "Extracting data files...\n"
     ]
    },
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadZipFile\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     24\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mData directory already exists\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mdownload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mdownload_data\u001b[39m\u001b[34m(force)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(data_dir) \u001b[38;5;129;01mor\u001b[39;00m force:\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExtracting data files...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[32m     21\u001b[39m         zip_ref.extractall(data_dir)\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mData extracted\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ds6001/lib/python3.12/zipfile/__init__.py:1354\u001b[39m, in \u001b[36mZipFile.__init__\u001b[39m\u001b[34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[39m\n\u001b[32m   1352\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1353\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1354\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1355\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   1356\u001b[39m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[32m   1357\u001b[39m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[32m   1358\u001b[39m         \u001b[38;5;28mself\u001b[39m._didModify = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ds6001/lib/python3.12/zipfile/__init__.py:1421\u001b[39m, in \u001b[36mZipFile._RealGetContents\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[33m\"\u001b[39m\u001b[33mFile is not a zip file\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1420\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[32m-> \u001b[39m\u001b[32m1421\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[33m\"\u001b[39m\u001b[33mFile is not a zip file\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.debug > \u001b[32m1\u001b[39m:\n\u001b[32m   1423\u001b[39m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[31mBadZipFile\u001b[39m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "def download_data(force=False):\n",
    "    \"\"\"Download and extract course data from Zenodo.\"\"\"\n",
    "    import urllib.request, zipfile, os\n",
    "    \n",
    "    zip_path = 'data.zip'\n",
    "    data_dir = 'data'\n",
    "    \n",
    "    if not os.path.exists(zip_path) or force:\n",
    "        print(\"Downloading course data\")\n",
    "        urllib.request.urlretrieve(\n",
    "            'https://zenodo.org/records/16954427/files/data.zip?download=1',\n",
    "            zip_path\n",
    "        )\n",
    "        print(\"Download complete\")\n",
    "    else:\n",
    "        print(\"Download file already exists\")\n",
    "        \n",
    "    if not os.path.exists(data_dir) or force:\n",
    "        print(\"Extracting data files...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(data_dir)\n",
    "        print(\"Data extracted\")\n",
    "    else:\n",
    "        print(\"Data directory already exists\")\n",
    "\n",
    "download_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01db0045",
   "metadata": {},
   "source": [
    "4. Open one of the datasets using Pandas:\n",
    "    1. `ames_prices.csv`: Housing characteristics and prices\n",
    "    2. `college_completion.csv`: Public, nonprofit, and for-profit educational institutions, graduation rates, and financial aid\n",
    "    3. `ForeignGifts_edu.csv`: Monetary and in-kind transfers from foreign entities to U.S. educational institutions\n",
    "    4. `iowa.csv`: Liquor sales in Iowa, at the transaction level\n",
    "    5. `metabric.csv`: Cancer patient and outcome data\n",
    "    6. `mn_police_use_of_force.csv`: Records of physical altercations between Minnessota police and private citizens\n",
    "    7. `nhanes_data_17_18.csv`: National Health and Nutrition Examination Survey\n",
    "    8. `tuna.csv`: Yellowfin Tuna Genome (I don't recommend this one; it's just a sequence of G, C, A, T )\n",
    "    9. `va_procurement.csv`: Public spending by the state of Virginia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5cade1",
   "metadata": {},
   "source": [
    "5. Pick two or three variables and briefly analyze them\n",
    "    - Is it a categorical or numeric variable?\n",
    "    - How many missing values are there? (`df['var'].isna()` and `np.sum()`)\n",
    "    - If categorical, tabulate the values (`df['var'].value_counts()`) and if numeric, get a summary (`df['var'].describe()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf2318a",
   "metadata": {},
   "source": [
    "6. What are some questions and prediction tools you could create using these data? Who would the stakeholder be for that prediction tool? What practical or ethical questions would it create? What other data would you want, that are not available in your data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a7ddc7",
   "metadata": {},
   "source": [
    "7. Commit your work to the repo (`git commit -am 'Finish assignment'` at the command line, or use the Git panel in VS Code). Push your work back to Github and submit the link on Canvas in the assignment tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca112c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 empty cells in the Cancer Type column.\n",
      "There are 0 empty cells in the Type of Breast Surgery column.\n",
      "There are 0 empty cells in the Chemotherapy column.\n",
      "There are 0 empty cells in the Hormone Therapy column.\n",
      "Both: 137\n",
      "Only Chemotherapy: 149\n",
      "Only Hormone Therapy: 674\n",
      "Neither: 383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndisplay(df[(df['Chemotherapy'] == 1) & (df['Hormone Therapy'] == False)])\\n\\n\\n6. \\nWhat are some questions and prediction tools you could create using these data? \\nWho would the stakeholder be for that prediction tool? \\nWhat practical or ethical questions would it create? \\nWhat other data would you want, that are not available in your data?\\n\\nA big question is about the age at diagnosis. This is important for detection and scanning - at what age should people be worried or start testing? And, at what ages are \\nchemo and hormone therapy useful? Another question is about treatment. Which treatment (or combination of treatments) lead to a survival status or a long overall survival in \\nmonths? A final question is if there is a correlation between the number of lymph nodes examined (positive) and tumor size and stage. Does checking more lymph nodes help catch\\ntumors at a smaller size or earlier stage? Or, do more positive lymph nodes correlate with larger or later-stage tumors? I am not sure what the lymph node category is saying \\nexactly, so either question would be answered after doing more research on what the column means. I could create multivariate graphs to answer these questions and see if \\np < 0.05 to relate the variables to each other, or, even better, build a predictive model using our ML class teachings! \\n\\nOf course, there is a lot of uncertainty with these data. What are the margins of error (if any)? What are the error rates/methods of checking to avoid errors when inputting \\nthe data? Are the variables simply correlated or causative? What columns depend on two or more columns, rather than just one (really, all of them, since medicine is very\\nholistic)? \\n\\nEthically, many questions are created. Choosing a cut-off age for regular scanning means younger individuals who are, in theory, low-risk, may miss detetion of a cancer. \\nRelying on an ML or predictive model alone to choose treatment can miss nuance that a human doctor can bring to the table. (Actually, studies have shown that a combination of \\nhuman choice AND AI-predictive decisions beat doctors or AI working alone. Teamwork!) Practically, can it create new indices like the Nottingham, that prognosticate? \\n\\nI would like to know if there are more treatments used than the three in the database. I also want to know if there are more prognosticative indices like the Nottingham one. \\nAre there varied ways to measure tumor size (mass vs dimensions)? Are there more physiological measures, like resting heart rate, weight, and blood pressure, that can be collected? \\nWhat about ages tested or scanned? \\n\\nA note: I am very interested in healthcare (and the environment) so loved this dataset and would enjoy seeing more examples in future assignments along these lines! Thank you!\\n\\n\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating df\n",
    "df = pd.read_csv(\"/Users/Caroline/Desktop/school/understanding_uncertainty/data/metabric.csv\")\n",
    "\n",
    "# Naming what columns I want to view and creating a df for that\n",
    "cols_to_view = ['Cancer Type', 'Type of Breast Surgery', 'Chemotherapy', 'Hormone Therapy']\n",
    "df_selected = df[cols_to_view]\n",
    "df_selected\n",
    "\n",
    "# QUESTION 5a\n",
    "# Cancer type is categorial; type of breast surgery is categorical; I feel like chemo and hormone therapy are numeric because I'd peronally replace YES/NO with 0/1\n",
    "# Upon second thought, 0/1 are still categories, so all my selected columns are categorical\n",
    "\n",
    "# QUESTION 5b\n",
    "for col in cols_to_view:\n",
    "    empty = df[col].isna()\n",
    "    print(f\"There are {np.sum(empty)} empty cells in the {col} column.\")\n",
    "# No columns have mising values. Great!\n",
    "\n",
    "# QUESTION 5c\n",
    "value_counts_cols = [df[col].value_counts() for col in cols_to_view]\n",
    "# print(value_counts_cols) (output copied below)\n",
    "\n",
    "\"\"\"\n",
    "Output:\n",
    "\n",
    "[\n",
    "Cancer Type:\n",
    "Breast Cancer    1343\n",
    "Name: count, dtype: int64, \n",
    "\n",
    "Type of Breast Surgery\n",
    "MASTECTOMY           773\n",
    "BREAST CONSERVING    570\n",
    "Name: count, dtype: int64, \n",
    "\n",
    "Chemotherapy\n",
    "NO     1057\n",
    "YES     286\n",
    "Name: count, dtype: int64, \n",
    "\n",
    "Hormone Therapy\n",
    "YES    811\n",
    "NO     532\n",
    "Name: count, dtype: int64\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "# NOTES ON QUESTION 5c\n",
    "# All cancers are breast cancer\n",
    "# 58% had mastectomies and 43% had breasts conserved\n",
    "    # Rounding keeps this from adding the 100%\n",
    "# 79% did not have chemo and 21% did.\n",
    "# 60% had hormone therapy and 40% did not.\n",
    "\n",
    "\n",
    "\n",
    "# Extra challenge: I want to explore how many had both chemotherapy and hormone therapy, how many had one, and how many had neither.\n",
    "# A bit of help from ChatGPT on putting df before [(df['Chemotherapy'] == 'YES') & (df['Hormone Therapy'] == 'NO')] and small error-checking.\n",
    "\n",
    "chemo = df[(df['Chemotherapy'] == 'YES') & (df['Hormone Therapy'] == 'NO')]\n",
    "hormone = df[(df['Chemotherapy'] == 'NO') & (df['Hormone Therapy'] == 'YES')]\n",
    "both = df[(df['Chemotherapy'] == 'YES') & (df['Hormone Therapy'] == 'YES')]\n",
    "neither = df[(df['Chemotherapy'] == 'NO') & (df['Hormone Therapy'] == 'NO')]\n",
    "\n",
    "\n",
    "# Print counts\n",
    "print(\"Both:\", len(both))\n",
    "print(\"Only Chemotherapy:\", len(chemo))\n",
    "print(\"Only Hormone Therapy:\", len(hormone))\n",
    "print(\"Neither:\", len(neither))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "6. \n",
    "What are some questions and prediction tools you could create using these data? \n",
    "Who would the stakeholder be for that prediction tool? \n",
    "What practical or ethical questions would it create? \n",
    "What other data would you want, that are not available in your data?\n",
    "\n",
    "A big question is about the age at diagnosis. This is important for detection and scanning - at what age should people be worried or start testing? And, at what ages are \n",
    "chemo and hormone therapy useful? Another question is about treatment. Which treatment (or combination of treatments) lead to a survival status or a long overall survival in \n",
    "months? A final question is if there is a correlation between the number of lymph nodes examined (positive) and tumor size and stage. Does checking more lymph nodes help catch\n",
    "tumors at a smaller size or earlier stage? Or, do more positive lymph nodes correlate with larger or later-stage tumors? I am not sure what the lymph node category is saying \n",
    "exactly, so either question would be answered after doing more research on what the column means. I could create multivariate graphs to answer these questions and see if \n",
    "p < 0.05 to relate the variables to each other, or, even better, build a predictive model using our ML class teachings! \n",
    "\n",
    "Of course, there is a lot of uncertainty with these data. What are the margins of error (if any)? What are the error rates/methods of checking to avoid errors when inputting \n",
    "the data? Are the variables simply correlated or causative? What columns depend on two or more columns, rather than just one (really, all of them, since medicine is very\n",
    "holistic)? \n",
    "\n",
    "Ethically, many questions are created. Choosing a cut-off age for regular scanning means younger individuals who are, in theory, low-risk, may miss detetion of a cancer. \n",
    "Relying on an ML or predictive model alone to choose treatment can miss nuance that a human doctor can bring to the table. (Actually, studies have shown that a combination of \n",
    "human choice AND AI-predictive decisions beat doctors or AI working alone. Teamwork!) Practically, can it create new indices like the Nottingham, that prognosticate? \n",
    "\n",
    "I would like to know if there are more treatments used than the three in the database. I also want to know if there are more prognosticative indices like the Nottingham one. \n",
    "Are there varied ways to measure tumor size (mass vs dimensions)? Are there more physiological measures, like resting heart rate, weight, and blood pressure, that can be collected? \n",
    "What about ages tested or scanned? \n",
    "\n",
    "A note: I am very interested in healthcare (and the environment) so loved this dataset and would enjoy seeing more examples in future assignments along these lines! Thank you!\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds6001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
